---
title: "Sprint 0: topology based refactoring and graph structure"
author: "Mike Johnson"
date: "`r Sys.Date()`"
output: html_document
out_dir: docs
editor_options: 
  markdown: 
    wrap: 72
---

# Goal

The goal  is to develop a workflow to modify hydrographic networks
to achieve more consistent catchment sizes. This work
aims to leverage existing products (e.g, the NHD) that already have a
delineated flow and catchment network.

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Dependencies
library(dplyr)
library(units)
library(sf)
library(lwgeom)
library(rmapshaper)
library(jsonlite)
lapply(list.files("../R", full.names = TRUE), source)

## Approximately 22,000 HUC10s in USA
huc10 <- "1805000502"
# Helpful
library(mapview)
library(ggplot2)
library(patchwork)
```

### Walker Data

We use the same sample 'Walker' data used in `hygeo`. It appears to be the
HUC10-1805000502. 

Whatever flowline data is used, it must have a **COMID, TONODE, FROMNODE, STREAMORE, LEVELPATHI, HYDROSEQ**. 

The catchment network must have a key **COMID**. 

**Area** and **length** can, and should, be calculated within the workflow so are unnecessary. 


### Read in Data

More test on data preparation and structure with go on [here](), but for now we prep the data
to make sure all names are lower case, that to, from and comids are represented as JSON, and the 
graph structure is more explicit.

```{r}
og_cat <- read_sf("../data/huc1805000502-catchment.gpkg") %>% 
   dplyr::select(comid = FEATUREID) %>% 
   mutate(areasqkm = as.numeric(set_units(st_area(.), "km2")))

og_fl = read_sf("../data/huc1805000502-flowlines.gpkg") %>% 
  prep_flownetwork()
```

Below we see the raw NHD data... there are three main problems:

  1) to many small catchments
  2) a lot of catchment topology errors
  3) complete misalignment between the flow and catchment networks at outlets!

```{r, echo  = FALSE}
mapview(og_cat) + og_fl
```

```{r, echo = FALSE}
make_plot = function(fl, cat, title, min, ideal, max){
  ggplot(cat, aes(x = areasqkm)) +
  geom_histogram() +
  geom_vline(xintercept = min, col = "gray20") +
  geom_vline(xintercept = ideal, col = "darkred") +
  geom_vline(xintercept = max, col = "gray20") +
  xlim(0, max+5) +
  labs(title = title,
       subtitle = paste(nrow(cat), "basins/flowlines")) +
  theme_bw() +
  ggplot(fl, aes(x = lengthkm)) +
  geom_histogram() +
  geom_vline(xintercept = .6) +
  geom_vline(xintercept = 5) +
  xlim(0, 15) + 
  theme_bw()
}

make_plot(og_fl, og_cat, "NHDPlus Raw", 3, 10, 15) 
```

### Catchment consolodation

Our refactoring will focus on catchment aggregation and will _NOT_ handle catchment
disaggregation. 

To start, we identify the headwater inlets in the AOI. Using these as
starting points we trace levelpaths downstream aggregating catchments as we go
aiming to preserve an "ideal catchment size" without exceeding a maximum catchment size. 
COMIDs are retained through the aggregation in a JSON notation. 

```{r}
agg_levelpath = aggregate_by_levelpath(og_fl, og_cat, 
                                       ideal_size = 10, 
                                       max_size = 15, max_length = 10)

mapview(agg_levelpath)
```

```{r, echo = FALSE}
make_plot(agg_levelpath$fl, agg_levelpath$cat, "Connectivity",  3, 10, 15) 
```

After "levelpath aggregation" we begin consuming catchments with sizes less then a minimum threshold, 
while enforcing a maximum threshold (both user defined). 
A stream order based logic is applied to aggregate smaller catchments into the larger components. 

At the end, only one flow path per catchment is retained and all
flowpaths are represented as LINESTRINGS.

```{r}
agg_size = aggregate_by_size(fl  = agg_levelpath$fl, 
                             cat = agg_levelpath$cat, 
                             min_size = 3,
                             max_size = 15)

mapview(agg_size)
```


```{r}
make_plot(agg_size$fl, agg_size$cat, "Aggregation", 2.5,10,15)
```

### {Graph}ing

After the flowline and catchment modifications, we need to re-create the network structure.
We do this by identifying the junctions, treating them all as nexus', and establishing a hierarchy of flow between nexi, 
flow paths, and respective catchments.

```{r}
nex_flow  = nexus_flow_graph(fl = agg_size$fl, cat = agg_size$cat)
mapview(nex_flow)
```

### Collapsing junctions

In some cases small flow paths can exist, as can basins that *could* be aggregated.
As one final pass we look to collapse any two-junction nexi, either into the nearest three-junction
nexi (defined by a threshold, km), or by collapsing basins with a single transfer/junction
into a single basin if less then the user define max_size. 

```{r}
junctions = collapse_junctions(nex_flow, og_cat, threshold = 1, max_size = 15)
mapview(junctions)
```

# Fix Edges

This is the first topology fix. It treats the flowline junctions as
"truth" and modifies the catchment vector topology such so there
is agreement between the catchment and flowpath network outlets.

There are areas of the NHD where a flowline crosses a catchment
boundary, in some cases this results in a chunk of a catchment belonging
to a catchment that is not part if the associated flowpath. This section
seeks to split, reunite and modify these areas.

```{r}
topo = topology_doctor(junctions)
mapview(topo)
```

```{r, echo = FALSE}
make_plot(topo$edges, topo$cat, "Size", 2.5, 10, 15) 
```

Returning to our three problems (in this basin at least!)

  1) [X] to many small catchments
  2) [X] a lot of catchment topology errors
  3) [X] complete misalignment between the flow and catchment networks at outlets!
  
# End of sprint 0
