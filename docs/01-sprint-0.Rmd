---
title: "Refactor Walker Basin"
author: "Mike Johnson"
date: "`r Sys.Date()`"
output: html_document
out_dir: docs
editor_options: 
  markdown: 
    wrap: 72
---

# Goal

The goal here is to develop a workflow to modify hydrographic networks
to achieve more consistent catchment sizes. This work
aims to leverage existing products (e.g, the NHD) that already have a
delineated flow and catchment network.

------------------------------------------------------------------------

The key tasks are to:

1.  [ ] Develop more *consistent and evenly distributed catchment sizes*
2.  [ ] Fix *topology errors* resulting from scalar mismatches in product
    creation
3.  [ ] Build a *referencing system* capable of handling network
    calculations
4.  [ ] Retain a indexing scheme that can allow these new identities to
    relate to there origin identities (e.g., cross walk
5.  [ ] Establish a addressing scheme that allows users to place hydrologic
    features (e.g., a stream gage) on to the network with precise
    spatial and hydrologic addressing.
6.  [ ] Develop an indexing scheme that can be applied at a continental
    scale, but that can allow areas to be processes piecemeal.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Dependencies
library(dplyr)

library(units)
library(sf)
library(lwgeom)
library(rmapshaper)

library(jsonlite)
library(tibble)

library(ggplot2)
library(patchwork)

## Approximately 22,000 HUC10s in USA
huc10 <- "1805000502"
# Helpful
library(mapview)
```

## Walker Data

We use the sample 'Walker' data from `hygeo`. It appears to be the
HUC10-1805000502. Whatever flowline data is used, it must have a
**COMID, TONODE, FROMNODE, STREAMORE, LEVELPATHI, HYDROSEQ**. 

The catchment network must have a **COMID**. **Area** and **length** can,
and should, be calculated within the workflow.

```{r}
source('../R/prep_flownetwork.R')

og_cat <- read_sf("../data/huc1805000502-catchment.gpkg") %>% 
   dplyr::select(comid = FEATUREID) %>% 
   mutate(areasqkm = as.numeric(set_units(st_area(.), "km2")))

og_fl = read_sf("../data/huc1805000502-flowlines.gpkg") %>% 
  prep_flownetwork(og_cat)
```

## Base Data:

```{r}
# Define with respect to square kilometers
mapview(og_cat) + og_fl
```

```{r, echo = FALSE}
make_plot = function(fl, cat, title, min, ideal, max){
  ggplot(cat, aes(x = areasqkm)) +
  geom_histogram() +
  geom_vline(xintercept = min, col = "gray20") +
  geom_vline(xintercept = ideal, col = "darkred") +
  geom_vline(xintercept = max, col = "gray20") +
  xlim(0, max+5) +
  labs(title = title,
       subtitle = paste(nrow(cat), "basins/flowlines")) +
  theme_bw() +
  ggplot(fl, aes(x = lengthkm)) +
  geom_density() +
  geom_vline(xintercept = .5) +
  geom_vline(xintercept = 5) +
  xlim(0, 15) + 
  theme_bw()
}

make_plot(og_fl, og_cat, "NHDPlus Raw", 3, 10, 15) 
```

To start, we identify the headwater inlets in the AOI. Using these as
starting points we trace levelpaths downstream aggregating catchments asw we go
aiming to preserve an "ideal catchment size". COMIDs are retained through
the aggregation in a JSON notation. At the end, the catchment and
flowpath COMIDs are aligned.

```{r}
source('../R/aggregate_by_levelpath.R')
agg_levelpath = aggregate_by_levelpath(og_fl, og_cat, ideal_size = 10, max_size = 15)
mapview(agg_levelpath$cat) + agg_levelpath$fl
```

```{r, echo = FALSE}
make_plot(agg_levelpath$fl, agg_levelpath$cat, "Connectivity",  3, 10, 15) 
```

After "levelpath aggregation" we begin consuming catchments with sizes less then a minimum threshold, while enforcing a maximum threshold (both user defined). A stream order based logic is applied to aggregate smaller catchments into larger component. The goal here is to align the flow network to the aggregated catchment
network such that there is only 1 flow line per catchment, and all
flowpaths are LINESTRINGS

```{r}
source('../R/aggregate_by_size.R')
agg_size = aggregate_by_size(fl  = agg_levelpath$fl, 
                             cat = agg_levelpath$cat, 
                             min_size = 3,
                             max_size = 15)

mapview(agg_size$cat) + agg_size$fl
```


```{r, echo = FALSE}
make_plot(agg_size$fl, agg_size$cat, "Size", 3, 10, 15) 
```

# Fix Edges

This is the first topology fix. It treats the flowline junctions as
"truth" and modifies the catchment polygon topology to such that there
is agreement between the cathment and flowpath networks.

There are areas of the NHD where a flowline crosses a catchment
boundary, in some cases this results in a chunk of a catchment belonging
to a catchment that is not part if the associated flowpath. This section
seeks to split, reunition and modify these areas.

```{r}
source('../R/topology_doctor.R')
topo_resolve = topology_doctor(fl = agg_size$fl, cat = agg_size$cat)
mapview(topo_resolve$cat[c("ID", "areasqkm")]) + topo_resolve$fl["ID"]
```

```{r, echo = FALSE}
make_plot(topo_resolve$fl, topo_resolve$cat, "Topo", 3, 10, 15)
```

## Indexing

```{r}
source('../R/nexi_flow_graph.R')
graph = nexus_flow_graph(fl = topo_resolve$fl, cat = topo_resolve$cat)

mapview(graph$nodes[c('nodeID', "count")], layer.name = "nodes", col.regions = "red", cex = 4) + 
mapview(graph$edges[c('ID', "ID2", "from", "to", "lengthkm")], layer.name = "edges") +
mapview(graph$cat[c('ID', 'areasqkm')], layer.name = "divides", col.regions = NA)
```

```{r}
source('../R/collapse_junctions.R')
graph = collapse_junctions(graph, og_catchments = og_cat, 1)

mapview(graph$nodes[c('nodeID', "count")], layer.name = "nodes", col.regions = "red", cex = 4) + 
mapview(graph$edges[c('ID', "ID2", "from", "to", "lengthkm")], layer.name = "edges") +
mapview(graph$cat[c('ID', 'areasqkm')], layer.name = "divides", col.regions = NA)
```

```{r, echo = FALSE}
make_plot(graph$edges, graph$cat, "Junction Snap", 3, 10, 15)
```

